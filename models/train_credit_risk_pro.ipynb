{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ›¡ï¸ Credit Risk Pro Model EÄŸitimi\n",
        "\n",
        "Bu notebook, **XGBoost Classifier** kullanarak detaylÄ± kredi risk tahmini iÃ§in optimize edilmiÅŸ bir model eÄŸitmektedir.\n",
        "\n",
        "## ğŸ“‹ Model Ã–zellikleri\n",
        "\n",
        "- **Model Tipi**: XGBoost (Extreme Gradient Boosting) Classifier\n",
        "- **DeÄŸiÅŸken SayÄ±sÄ±**: 16 deÄŸiÅŸken (13 temel + 3 tÃ¼retilmiÅŸ)\n",
        "- **KullanÄ±m AmacÄ±**: DetaylÄ± risk analizi iÃ§in optimize edilmiÅŸ model\n",
        "- **Optimizasyon**: RandomizedSearchCV ile hiperparametre optimizasyonu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CREDIT RISK PRO MODEL EÄÄ°TÄ°MÄ°\")\n",
        "print(\"=\" * 80)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‚ 2. Veri YÃ¼kleme\n",
        "\n",
        "Bu adÄ±mda, Lending Club veri setini yÃ¼klÃ¼yoruz. Bu veri seti gerÃ§ek kredi verilerini iÃ§ermektedir.\n",
        "\n",
        "**Veri Seti**: `lending_club_cleaned.csv`\n",
        "- Toplam kayÄ±t sayÄ±sÄ±nÄ± ve sÃ¼tun sayÄ±sÄ±nÄ± kontrol ediyoruz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri dosyasÄ±nÄ± yÃ¼kle\n",
        "INPUT_FILE = 'lending_club_cleaned.csv'\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "print(f\"Toplam kayÄ±t: {len(df)}\")\n",
        "print(f\"SÃ¼tun sayÄ±sÄ±: {len(df.columns)}\")\n",
        "print(f\"\\nÄ°lk 5 satÄ±r:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ 3. Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, model performansÄ±nÄ± artÄ±rmak iÃ§in yeni Ã¶zellikler tÃ¼retiyoruz:\n",
        "\n",
        "### TÃ¼retilmiÅŸ Ã–zellikler:\n",
        "- **loan_to_income**: Kredi tutarÄ± / YÄ±llÄ±k gelir oranÄ±\n",
        "  - Bu oran, mÃ¼ÅŸterinin kredi yÃ¼kÃ¼mlÃ¼lÃ¼ÄŸÃ¼nÃ¼n gelirine gÃ¶re ne kadar bÃ¼yÃ¼k olduÄŸunu gÃ¶sterir\n",
        "  \n",
        "- **installment_to_income**: AylÄ±k taksit / AylÄ±k gelir oranÄ± (PTI - Payment-to-Income)\n",
        "  - MÃ¼ÅŸterinin aylÄ±k gelirinin ne kadarÄ±nÄ± kredi taksitine ayÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶sterir\n",
        "  - YÃ¼ksek PTI deÄŸerleri, finansal sÄ±kÄ±ÅŸÄ±klÄ±k sinyali verebilir\n",
        "  \n",
        "- **balance_income_ratio**: DÃ¶ner kredi bakiyesi / YÄ±llÄ±k gelir oranÄ±\n",
        "  - MÃ¼ÅŸterinin dÃ¶ner kredi borcunun gelirine gÃ¶re ne kadar bÃ¼yÃ¼k olduÄŸunu gÃ¶sterir\n",
        "\n",
        "### SeÃ§ilen Ã–zellikler (16 deÄŸiÅŸken):\n",
        "1. **loan_amnt**: Kredi tutarÄ±\n",
        "2. **annual_inc**: YÄ±llÄ±k gelir\n",
        "3. **installment**: AylÄ±k taksit\n",
        "4. **int_rate**: Faiz oranÄ±\n",
        "5. **dti**: Debt-to-Income ratio (BorÃ§/Gelir oranÄ±)\n",
        "6. **fico_range_low**: FICO kredi skoru (dÃ¼ÅŸÃ¼k)\n",
        "7. **fico_range_high**: FICO kredi skoru (yÃ¼ksek)\n",
        "8. **revol_bal**: DÃ¶ner kredi bakiyesi\n",
        "9. **revol_util**: DÃ¶ner kredi kullanÄ±m oranÄ±\n",
        "10. **total_acc**: Toplam hesap sayÄ±sÄ±\n",
        "11. **open_acc**: AÃ§Ä±k hesap sayÄ±sÄ±\n",
        "12. **pub_rec**: Kamu kayÄ±tlarÄ±\n",
        "13. **inq_last_6mths**: Son 6 ayda sorgulama sayÄ±sÄ±\n",
        "14. **loan_to_income**: TÃ¼retilmiÅŸ Ã¶zellik\n",
        "15. **installment_to_income**: TÃ¼retilmiÅŸ Ã¶zellik (PTI)\n",
        "16. **balance_income_ratio**: TÃ¼retilmiÅŸ Ã¶zellik\n",
        "\n",
        "### Kategorik DeÄŸiÅŸkenler:\n",
        "- **home_ownership**: Ev durumu (KiracÄ±, Ev sahibi, vb.)\n",
        "- **purpose**: Kredi amacÄ±\n",
        "- **grade**: Kredi notu (A, B, C, D, E, F, G)\n",
        "- **emp_length**: Ä°stihdam sÃ¼resi\n",
        "- **verification_status**: Gelir doÄŸrulama durumu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ¼retilmiÅŸ Ã¶zellikler\n",
        "# 1. loan_to_income: Kredi tutarÄ± / YÄ±llÄ±k gelir\n",
        "df['loan_to_income'] = df['loan_amnt'] / (df['annual_inc'] + 1)\n",
        "\n",
        "# 2. installment_to_income: AylÄ±k taksit / AylÄ±k gelir (PTI - Payment-to-Income)\n",
        "df['installment_to_income'] = df['installment'] / ((df['annual_inc'] / 12) + 1)\n",
        "\n",
        "# 3. balance_income_ratio: DÃ¶ner kredi bakiyesi / YÄ±llÄ±k gelir\n",
        "df['balance_income_ratio'] = df['revol_bal'] / (df['annual_inc'] + 1)\n",
        "\n",
        "# Pro Model iÃ§in 16 deÄŸiÅŸken seÃ§imi (13 temel + 3 tÃ¼retilmiÅŸ)\n",
        "pro_features = [\n",
        "    'loan_amnt',              # Kredi tutarÄ±\n",
        "    'annual_inc',             # YÄ±llÄ±k gelir\n",
        "    'installment',            # AylÄ±k taksit\n",
        "    'int_rate',              # Faiz oranÄ±\n",
        "    'dti',                   # Debt-to-Income ratio\n",
        "    'fico_range_low',        # FICO skoru (dÃ¼ÅŸÃ¼k)\n",
        "    'fico_range_high',       # FICO skoru (yÃ¼ksek)\n",
        "    'revol_bal',             # DÃ¶ner kredi bakiyesi\n",
        "    'revol_util',            # DÃ¶ner kredi kullanÄ±m oranÄ±\n",
        "    'total_acc',             # Toplam hesap sayÄ±sÄ±\n",
        "    'open_acc',              # AÃ§Ä±k hesap sayÄ±sÄ±\n",
        "    'pub_rec',               # Kamu kayÄ±tlarÄ±\n",
        "    'inq_last_6mths',       # Son 6 ayda sorgulama sayÄ±sÄ±\n",
        "    'loan_to_income',        # TÃ¼retilmiÅŸ: Kredi tutarÄ± / YÄ±llÄ±k gelir\n",
        "    'installment_to_income', # TÃ¼retilmiÅŸ: AylÄ±k taksit / AylÄ±k gelir (PTI)\n",
        "    'balance_income_ratio'  # TÃ¼retilmiÅŸ: DÃ¶ner kredi bakiyesi / YÄ±llÄ±k gelir\n",
        "]\n",
        "\n",
        "# Kategorik deÄŸiÅŸkenler (One-Hot Encoding iÃ§in)\n",
        "categorical_features = ['home_ownership', 'purpose', 'grade', 'emp_length', 'verification_status']\n",
        "\n",
        "# Hedef deÄŸiÅŸken\n",
        "target = 'loan_status_binary'  # 0: Ã–dendi, 1: TemerrÃ¼t\n",
        "\n",
        "# Veri hazÄ±rlama\n",
        "X = df[pro_features + categorical_features].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "print(f\"SeÃ§ilen Ã¶zellik sayÄ±sÄ±: {len(pro_features)} temel + {len(categorical_features)} kategorik\")\n",
        "print(f\"\\nTÃ¼retilmiÅŸ Ã¶zellikler:\")\n",
        "print(f\"  - loan_to_income: Kredi tutarÄ± / YÄ±llÄ±k gelir\")\n",
        "print(f\"  - installment_to_income: AylÄ±k taksit / AylÄ±k gelir (PTI)\")\n",
        "print(f\"  - balance_income_ratio: DÃ¶ner kredi bakiyesi / YÄ±llÄ±k gelir\")\n",
        "print(f\"\\nHedef deÄŸiÅŸken daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(f\"  0 (Ã–dendi): {(y == 0).sum()} ({(y == 0).sum() / len(y) * 100:.2f}%)\")\n",
        "print(f\"  1 (TemerrÃ¼t): {(y == 1).sum()} ({(y == 1).sum() / len(y) * 100:.2f}%)\")\n",
        "print(f\"\\nTÃ¼retilmiÅŸ Ã¶zellik istatistikleri:\")\n",
        "print(df[['loan_to_income', 'installment_to_income', 'balance_income_ratio']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§¹ 4. Veri Ã–n Ä°ÅŸleme (Preprocessing)\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, eksik deÄŸerleri dolduruyoruz ve kategorik deÄŸiÅŸkenleri sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.\n",
        "\n",
        "### Eksik DeÄŸer Ä°ÅŸleme:\n",
        "- **SayÄ±sal deÄŸiÅŸkenler**: Medyan ile doldurulur (aykÄ±rÄ± deÄŸerlere daha dayanÄ±klÄ±)\n",
        "- **Kategorik deÄŸiÅŸkenler**: Mod (en sÄ±k gÃ¶rÃ¼len deÄŸer) ile doldurulur\n",
        "\n",
        "### One-Hot Encoding:\n",
        "- Kategorik deÄŸiÅŸkenler binary (0/1) sÃ¼tunlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r\n",
        "- Her kategori iÃ§in ayrÄ± bir sÃ¼tun oluÅŸturulur\n",
        "- Multicollinearity Ã¶nlemek iÃ§in ilk kategori dÃ¼ÅŸÃ¼rÃ¼lÃ¼r (`drop='first'`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eksik deÄŸer kontrolÃ¼\n",
        "print(\"Eksik deÄŸer kontrolÃ¼:\")\n",
        "missing_summary = X.isnull().sum()\n",
        "for col in X.columns:\n",
        "    missing = missing_summary[col]\n",
        "    if missing > 0:\n",
        "        print(f\"  {col}: {missing} eksik deÄŸer ({missing/len(X)*100:.2f}%)\")\n",
        "\n",
        "# Eksik deÄŸerleri doldur\n",
        "# SayÄ±sal deÄŸiÅŸkenler iÃ§in medyan kullanÄ±yoruz (aykÄ±rÄ± deÄŸerlere daha dayanÄ±klÄ±)\n",
        "for col in pro_features:\n",
        "    if X[col].isnull().sum() > 0:\n",
        "        median_val = X[col].median()\n",
        "        X[col].fillna(median_val, inplace=True)\n",
        "        print(f\"  {col}: {X[col].isnull().sum()} eksik deÄŸer medyan ({median_val:.2f}) ile dolduruldu\")\n",
        "\n",
        "# Kategorik deÄŸiÅŸkenler iÃ§in mod (en sÄ±k gÃ¶rÃ¼len deÄŸer) kullanÄ±yoruz\n",
        "for col in categorical_features:\n",
        "    if X[col].isnull().sum() > 0:\n",
        "        mode_val = X[col].mode()[0] if len(X[col].mode()) > 0 else 'Unknown'\n",
        "        X[col].fillna(mode_val, inplace=True)\n",
        "        print(f\"  {col}: {X[col].isnull().sum()} eksik deÄŸer mod ({mode_val}) ile dolduruldu\")\n",
        "\n",
        "print(f\"\\nToplam eksik deÄŸer sayÄ±sÄ±: {X.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-Hot Encoding iÃ§in ColumnTransformer\n",
        "# ColumnTransformer, farklÄ± sÃ¼tunlara farklÄ± dÃ¶nÃ¼ÅŸÃ¼mler uygulamamÄ±za olanak saÄŸlar\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', pro_features),  # SayÄ±sal Ã¶zellikler olduÄŸu gibi geÃ§irilir\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "        # Kategorik Ã¶zellikler One-Hot Encoding ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r\n",
        "        # drop='first': Ä°lk kategoriyi dÃ¼ÅŸÃ¼r (multicollinearity Ã¶nleme)\n",
        "        # handle_unknown='ignore': EÄŸitim sÄ±rasÄ±nda gÃ¶rÃ¼lmeyen kategorileri yok say\n",
        "        # sparse_output=False: Dense array dÃ¶ndÃ¼r (numpy array)\n",
        "    ],\n",
        "    remainder='drop'  # Belirtilmeyen sÃ¼tunlarÄ± dÃ¼ÅŸÃ¼r\n",
        ")\n",
        "\n",
        "# Preprocessing uygula\n",
        "print(\"Preprocessing uygulanÄ±yor...\")\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Ã–zellik isimlerini al (One-Hot Encoding sonrasÄ± oluÅŸan yeni sÃ¼tunlar dahil)\n",
        "feature_names = pro_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "\n",
        "print(f\"Ä°ÅŸlenmiÅŸ Ã¶zellik sayÄ±sÄ±: {X_processed.shape[1]}\")\n",
        "print(f\"One-Hot Encoding uygulandÄ±\")\n",
        "print(f\"Orijinal Ã¶zellik sayÄ±sÄ±: {len(pro_features) + len(categorical_features)}\")\n",
        "print(f\"Yeni Ã¶zellik sayÄ±sÄ±: {X_processed.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ‚ï¸ 5. Veri BÃ¶lme (Train-Test Split)\n",
        "\n",
        "Modelin genelleme yeteneÄŸini test etmek iÃ§in veriyi eÄŸitim ve test setlerine ayÄ±rÄ±yoruz:\n",
        "\n",
        "- **Train Set**: Model eÄŸitimi iÃ§in kullanÄ±lacak (%80)\n",
        "- **Test Set**: Model performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lacak (%20)\n",
        "- **Stratify**: Hedef deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nÄ± her iki sette de korur (sÄ±nÄ±f dengesizliÄŸi iÃ§in Ã¶nemli)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri bÃ¶lme\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y, \n",
        "    test_size=0.2,  # %20 test seti\n",
        "    stratify=y  # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koru\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} kayÄ±t ({X_train.shape[0]/len(X_processed)*100:.1f}%)\")\n",
        "print(f\"Test set: {X_test.shape[0]} kayÄ±t ({X_test.shape[0]/len(X_processed)*100:.1f}%)\")\n",
        "print(f\"\\nTrain set hedef daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(f\"  0 (Ã–dendi): {(y_train == 0).sum()} ({(y_train == 0).sum() / len(y_train) * 100:.2f}%)\")\n",
        "print(f\"  1 (TemerrÃ¼t): {(y_train == 1).sum()} ({(y_train == 1).sum() / len(y_train) * 100:.2f}%)\")\n",
        "print(f\"\\nTest set hedef daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(f\"  0 (Ã–dendi): {(y_test == 0).sum()} ({(y_test == 0).sum() / len(y_test) * 100:.2f}%)\")\n",
        "print(f\"  1 (TemerrÃ¼t): {(y_test == 1).sum()} ({(y_test == 1).sum() / len(y_test) * 100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ 6. Model EÄŸitimi ve Hiperparametre Optimizasyonu\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, XGBoost modelini eÄŸitiyoruz ve en iyi hiperparametreleri bulmak iÃ§in **RandomizedSearchCV** kullanÄ±yoruz.\n",
        "\n",
        "### RandomizedSearchCV Nedir?\n",
        "- GridSearchCV'nin daha hÄ±zlÄ± alternatifi\n",
        "- Belirtilen parametre uzayÄ±ndan **rastgele** kombinasyonlar seÃ§er\n",
        "- TÃ¼m kombinasyonlarÄ± denemek yerine, belirli sayÄ±da kombinasyonu test eder\n",
        "- Daha hÄ±zlÄ± sonuÃ§ verir, ancak global optimum'u garanti etmez\n",
        "\n",
        "### Test Edilen Parametreler:\n",
        "- **n_estimators**: AÄŸaÃ§ sayÄ±sÄ± (200, 300, 350, 400, 500)\n",
        "- **learning_rate**: Ã–ÄŸrenme hÄ±zÄ± (0.01, 0.03, 0.05, 0.1)\n",
        "- **max_depth**: AÄŸaÃ§ derinliÄŸi (3, 4, 5, 6)\n",
        "- **subsample**: Alt Ã¶rnekleme oranÄ± (0.7, 0.75, 0.8, 0.9)\n",
        "- **colsample_bytree**: SÃ¼tun alt Ã¶rnekleme (0.7, 0.75, 0.8)\n",
        "- **min_child_weight**: Minimum Ã§ocuk aÄŸÄ±rlÄ±ÄŸÄ± (1, 2, 3)\n",
        "- **gamma**: Minimum kayÄ±p azaltma (0, 0.1, 0.2)\n",
        "\n",
        "### Optimizasyon Stratejisi:\n",
        "- **100 kombinasyon** test edilecek\n",
        "- **3-fold Cross Validation** ile her kombinasyon deÄŸerlendirilecek\n",
        "- **Scoring metrik**: ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base model (varsayÄ±lan parametrelerle)\n",
        "base_model = XGBClassifier(\n",
        "    eval_metric='logloss',  # Binary classification iÃ§in logloss kullan\n",
        "    use_label_encoder=False,  # Label encoder kullanma (deprecated)\n",
        "    n_jobs=-1,  # TÃ¼m CPU Ã§ekirdeklerini kullan\n",
        "    verbosity=0  # Ã‡Ä±ktÄ±larÄ± gizle\n",
        ")\n",
        "\n",
        "# Hiperparametre arama uzayÄ±\n",
        "param_distributions = {\n",
        "    'n_estimators': [200, 300, 350, 400, 500],  # AÄŸaÃ§ sayÄ±sÄ±\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.1],  # Ã–ÄŸrenme hÄ±zÄ±\n",
        "    'max_depth': [3, 4, 5, 6],  # AÄŸaÃ§ derinliÄŸi\n",
        "    'subsample': [0.7, 0.75, 0.8, 0.9],  # Alt Ã¶rnekleme oranÄ±\n",
        "    'colsample_bytree': [0.7, 0.75, 0.8],  # SÃ¼tun alt Ã¶rnekleme\n",
        "    'min_child_weight': [1, 2, 3],  # Minimum Ã§ocuk aÄŸÄ±rlÄ±ÄŸÄ±\n",
        "    'gamma': [0, 0.1, 0.2]  # Minimum kayÄ±p azaltma\n",
        "}\n",
        "\n",
        "print(\"Hiperparametre optimizasyonu baÅŸlatÄ±lÄ±yor...\")\n",
        "print(\"RandomizedSearchCV ile 100 kombinasyon test edilecek (3-fold CV)...\")\n",
        "print(\"Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir...\\n\")\n",
        "\n",
        "# RandomizedSearchCV ile optimizasyon\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,  # 100 rastgele kombinasyon test et\n",
        "    cv=3,  # 3-fold cross validation\n",
        "    scoring='roc_auc',  # ROC-AUC skorunu optimize et\n",
        "    n_jobs=-1,  # Paralel iÅŸleme\n",
        "    verbose=1  # Ä°lerleme bilgisi gÃ¶ster\n",
        ")\n",
        "\n",
        "# Optimizasyonu Ã§alÄ±ÅŸtÄ±r\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OPTÄ°MÄ°ZASYON TAMAMLANDI!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nEn iyi parametreler:\")\n",
        "best_params = random_search.best_params_\n",
        "for param, value in best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"\\nEn iyi CV skoru (ROC-AUC): {random_search.best_score_:.4f} ({random_search.best_score_*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ 7. Final Model EÄŸitimi\n",
        "\n",
        "En iyi hiperparametrelerle final modeli eÄŸitiyoruz. Bu model, tÃ¼m eÄŸitim seti Ã¼zerinde eÄŸitilecek.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final model (en iyi parametrelerle)\n",
        "final_model = XGBClassifier(\n",
        "    **best_params,  # En iyi parametreleri kullan\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "print(\"Final model eÄŸitiliyor...\")\n",
        "final_model.fit(X_train, y_train)\n",
        "print(\"EÄŸitim tamamlandÄ±!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 8. Model DeÄŸerlendirme\n",
        "\n",
        "Model performansÄ±nÄ± test seti Ã¼zerinde deÄŸerlendiriyoruz. AÅŸaÄŸÄ±daki metrikleri hesaplÄ±yoruz:\n",
        "\n",
        "### KullanÄ±lan Metrikler:\n",
        "1. **Accuracy**: DoÄŸru tahmin oranÄ±\n",
        "2. **ROC-AUC**: SÄ±nÄ±flandÄ±rma kalitesi (0.5 = rastgele, 1.0 = mÃ¼kemmel)\n",
        "3. **Precision**: Pozitif tahminlerin doÄŸruluÄŸu\n",
        "4. **Recall**: GerÃ§ek pozitiflerin ne kadarÄ±nÄ± yakaladÄ±ÄŸÄ±mÄ±z\n",
        "5. **F1-Score**: Precision ve Recall'un harmonik ortalamasÄ±\n",
        "\n",
        "AyrÄ±ca **5-fold Cross Validation** ile modelin kararlÄ±lÄ±ÄŸÄ±nÄ± test ediyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test set tahminleri\n",
        "y_pred = final_model.predict(X_test)  # SÄ±nÄ±f tahminleri (0 veya 1)\n",
        "y_pred_proba = final_model.predict_proba(X_test)[:, 1]  # OlasÄ±lÄ±k tahminleri (0-1 arasÄ±)\n",
        "\n",
        "# Metrikler\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "test_precision = precision_score(y_test, y_pred)\n",
        "test_recall = recall_score(y_test, y_pred)\n",
        "test_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MODEL PERFORMANS METRÄ°KLERÄ° (TEST SET)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Accuracy:        {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"ROC-AUC:         {test_roc_auc:.4f} ({test_roc_auc*100:.2f}%)\")\n",
        "print(f\"Precision:       {test_precision:.4f} ({test_precision*100:.2f}%)\")\n",
        "print(f\"Recall:          {test_recall:.4f} ({test_recall*100:.2f}%)\")\n",
        "print(f\"F1-Score:        {test_f1:.4f} ({test_f1*100:.2f}%)\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation skorlarÄ± (model kararlÄ±lÄ±ÄŸÄ±nÄ± test etmek iÃ§in)\n",
        "print(\"Cross-Validation SkorlarÄ± (5-fold):\")\n",
        "cv_scores = cross_val_score(final_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "print(f\"  ROC-AUC Ortalama: {cv_scores.mean():.4f} ({cv_scores.mean()*100:.2f}%)\")\n",
        "print(f\"  ROC-AUC Std Sapma: {cv_scores.std():.4f} ({cv_scores.std()*100:.2f}%)\")\n",
        "print(f\"  ROC-AUC Min: {cv_scores.min():.4f} ({cv_scores.min()*100:.2f}%)\")\n",
        "print(f\"  ROC-AUC Max: {cv_scores.max():.4f} ({cv_scores.max()*100:.2f}%)\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Report (detaylÄ± metrikler)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ã–dendi', 'TemerrÃ¼t']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¾ 9. Model Kaydetme\n",
        "\n",
        "EÄŸitilmiÅŸ modeli, preprocessor'Ä± ve ilgili bilgileri bir paket halinde kaydediyoruz. Bu paket, daha sonra modeli yÃ¼kleyip kullanmak iÃ§in gereklidir.\n",
        "\n",
        "**Kaydedilen Dosya**: `credit_risk_model_20fold.pkl`\n",
        "\n",
        "**Ä°Ã§erik**:\n",
        "- EÄŸitilmiÅŸ model\n",
        "- Preprocessor (veri Ã¶n iÅŸleme pipeline'Ä±)\n",
        "- Ã–zellik isimleri\n",
        "- En iyi hiperparametreler\n",
        "- Test set performans metrikleri\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model ve preprocessor'Ä± birlikte kaydet\n",
        "model_package = {\n",
        "    'model': final_model,\n",
        "    'preprocessor': preprocessor,\n",
        "    'feature_names': feature_names,\n",
        "    'best_params': best_params,\n",
        "    'test_accuracy': test_accuracy,\n",
        "    'test_roc_auc': test_roc_auc\n",
        "}\n",
        "\n",
        "output_file = 'credit_risk_model_20fold.pkl'\n",
        "joblib.dump(model_package, output_file)\n",
        "print(f\"âœ… Model baÅŸarÄ±yla kaydedildi: {output_file}\")\n",
        "print(f\"\\nKaydedilen bilgiler:\")\n",
        "print(f\"  - Model: XGBoost Classifier\")\n",
        "print(f\"  - Preprocessor: ColumnTransformer\")\n",
        "print(f\"  - Ã–zellik sayÄ±sÄ±: {len(feature_names)}\")\n",
        "print(f\"  - Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"  - Test ROC-AUC: {test_roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ‰ EÄÄ°TÄ°M TAMAMLANDI!\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
