"""
NBA (Next Best Action) K-Means Clustering Model EÄŸitim Scripti
K-Means Clustering - 6 kÃ¼me
MÃ¼ÅŸteri segmentasyonu iÃ§in optimize edilmiÅŸ model
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("NBA K-MEANS CLUSTERING MODEL EÄÄ°TÄ°MÄ°")
print("K-Means Clustering - 6 KÃ¼me")
print("=" * 80)
print()

# --- 1. VERÄ° YÃœKLEME ---
print(">>> [1/5] Veri yÃ¼kleniyor...")
INPUT_FILE = 'datasets/bank_customer_churn_data/Customer-Churn-Records.csv'
df = pd.read_csv(INPUT_FILE)
print(f"   Toplam kayÄ±t: {len(df)}")
print(f"   SÃ¼tun sayÄ±sÄ±: {len(df.columns)}")
print()

# --- 2. Ã–ZELLÄ°K SEÃ‡Ä°MÄ° ---
print(">>> [2/5] Ã–zellik seÃ§imi yapÄ±lÄ±yor...")

# K-Means iÃ§in seÃ§ilen Ã¶zellikler
features = ['Balance', 'EstimatedSalary', 'NumOfProducts', 'Tenure', 'IsActiveMember']

X = df[features].copy()

print(f"   SeÃ§ilen Ã¶zellikler ({len(features)}):")
for i, feat in enumerate(features, 1):
    print(f"     {i}. {feat}")
print()

# Eksik deÄŸer kontrolÃ¼
print("   Eksik deÄŸer kontrolÃ¼:")
missing_count = X.isnull().sum().sum()
if missing_count > 0:
    print(f"     Toplam eksik deÄŸer: {missing_count}")
    for col in features:
        missing = X[col].isnull().sum()
        if missing > 0:
            print(f"       {col}: {missing} eksik deÄŸer")
            X[col].fillna(X[col].median(), inplace=True)
    print("     Eksik deÄŸerler medyan ile dolduruldu")
else:
    print("     Eksik deÄŸer yok")
print()

# --- 3. VERÄ° Ã–N Ä°ÅLEME (NORMALÄ°ZASYON) ---
print(">>> [3/5] Veri normalizasyonu yapÄ±lÄ±yor...")

# MinMaxScaler ile 0-1 arasÄ±na Ã¶lÃ§eklendirme
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

print(f"   MinMaxScaler uygulandÄ±")
print(f"   Ã–zellikler 0-1 arasÄ±na Ã¶lÃ§eklendirildi")
print(f"   Ä°ÅŸlenmiÅŸ veri boyutu: {X_scaled.shape}")
print()

# Ã–zellik istatistikleri (normalize edilmiÅŸ)
print("   Normalize edilmiÅŸ Ã¶zellik istatistikleri:")
for i, feat in enumerate(features):
    print(f"     {feat}:")
    print(f"       Min: {X_scaled[:, i].min():.4f}")
    print(f"       Max: {X_scaled[:, i].max():.4f}")
    print(f"       Mean: {X_scaled[:, i].mean():.4f}")
    print(f"       Std: {X_scaled[:, i].std():.4f}")
print()

# --- 4. K-MEANS CLUSTERING ---
print(">>> [4/5] K-Means clustering yapÄ±lÄ±yor...")

# K-Means parametreleri
N_CLUSTERS = 6
N_INIT = 10000  # 10,000 farklÄ± baÅŸlangÄ±Ã§ noktasÄ±
MAX_ITER = 300

print(f"   Parametreler:")
print(f"     n_clusters: {N_CLUSTERS}")
print(f"     n_init: {N_INIT} (10,000 farklÄ± baÅŸlangÄ±Ã§ noktasÄ±)")
print(f"     max_iter: {MAX_ITER}")
print()
print("   Model eÄŸitiliyor (bu iÅŸlem biraz zaman alabilir)...")

# K-Means modeli
kmeans = KMeans(
    n_clusters=N_CLUSTERS,
    n_init=N_INIT,
    max_iter=MAX_ITER,
    n_jobs=-1
)

# Model eÄŸitimi
kmeans.fit(X_scaled)

# KÃ¼me etiketleri
cluster_labels = kmeans.predict(X_scaled)
df['Cluster_Label'] = cluster_labels

print("   EÄŸitim tamamlandÄ±!")
print()

# --- 5. MODEL DOÄRULAMA (SILHOUETTE SCORE) ---
print(">>> [5/5] Model doÄŸrulama (Silhouette Score)...")

# Silhouette Score hesaplama (Ã¶rneklem boyutu sÄ±nÄ±rlÄ±)
sample_size = min(2000, len(X_scaled))
sil_score = silhouette_score(X_scaled[:sample_size], cluster_labels[:sample_size])

print(f"   Silhouette Score: {sil_score:.4f}")
print(f"   Yorumlama:")
if sil_score >= 0.5:
    print("     MÃ¼kemmel: KÃ¼meler Ã§ok iyi ayrÄ±lmÄ±ÅŸ")
elif sil_score >= 0.3:
    print("     Ä°yi: KÃ¼meler kabul edilebilir ÅŸekilde ayrÄ±lmÄ±ÅŸ")
elif sil_score >= 0.1:
    print("     Orta: KÃ¼meler birbirine yakÄ±n")
else:
    print("     ZayÄ±f: KÃ¼meler Ã§ok yakÄ±n veya kÃ¶tÃ¼ ayrÄ±lmÄ±ÅŸ")
print()

# --- 6. SEGMENT ANALÄ°ZÄ° ---
print("=" * 80)
print("SEGMENT ANALÄ°ZÄ°")
print("=" * 80)
print()

# Her kÃ¼me iÃ§in istatistikler
centroids = kmeans.cluster_centers_
segment_stats = {}

for i in range(N_CLUSTERS):
    cluster_data = df[df['Cluster_Label'] == i]
    segment_stats[i] = {
        'size': len(cluster_data),
        'avg_balance': cluster_data['Balance'].mean(),
        'avg_salary': cluster_data['EstimatedSalary'].mean(),
        'avg_products': cluster_data['NumOfProducts'].mean(),
        'avg_tenure': cluster_data['Tenure'].mean(),
        'avg_active': cluster_data['IsActiveMember'].mean(),
        'centroid': centroids[i]
    }

# Segment isimlendirme (centroid analizine gÃ¶re)
cluster_scores = []
for i in range(N_CLUSTERS):
    stats = segment_stats[i]
    center = centroids[i]
    total_score = (center[0] * 0.3 + center[1] * 0.3 + center[2] * 0.2 + 
                  center[3] * 0.1 + center[4] * 0.1)
    cluster_scores.append((i, total_score, stats))

cluster_scores.sort(key=lambda x: x[1], reverse=True)

segment_templates = [
    "ğŸ’ Elit / Servet YÃ¶netimi",
    "ğŸš€ Dinamik / Aktif MÃ¼ÅŸteri", 
    "ğŸ’° GÃ¼venli / Birikimci",
    "âš ï¸ Riskli / Pasif MÃ¼ÅŸteri",
    "ğŸŒ± Temel Mevduat / GiriÅŸ",
    "ğŸ“Š Standart BankacÄ±lÄ±k"
]

cluster_names = {}
for rank, (cluster_id, total_score, stats) in enumerate(cluster_scores):
    cluster_names[cluster_id] = segment_templates[rank]

df['Segment_Name'] = df['Cluster_Label'].map(cluster_names)

# Segment istatistiklerini yazdÄ±r
print("Segment Ä°statistikleri:")
print("-" * 80)
for i in range(N_CLUSTERS):
    stats = segment_stats[i]
    name = cluster_names[i]
    print(f"\n{i}. {name}")
    print(f"   Ãœye SayÄ±sÄ±: {stats['size']} ({(stats['size']/len(df)*100):.2f}%)")
    print(f"   Ortalama Bakiye: ${stats['avg_balance']:,.2f}")
    print(f"   Ortalama MaaÅŸ: ${stats['avg_salary']:,.2f}")
    print(f"   Ortalama ÃœrÃ¼n SayÄ±sÄ±: {stats['avg_products']:.2f}")
    print(f"   Ortalama Tenure: {stats['avg_tenure']:.2f} yÄ±l")
    print(f"   Aktif Ãœye OranÄ±: {stats['avg_active']:.2%}")
print()

# --- 7. MODEL KAYDETME ---
print("=" * 80)
print("MODEL KAYDEDÄ°LÄ°YOR...")
print("=" * 80)

# Model package
model_package = {
    'kmeans': kmeans,
    'scaler': scaler,
    'features': features,
    'cluster_names': cluster_names,
    'silhouette_score': sil_score,
    'n_clusters': N_CLUSTERS,
    'segment_stats': segment_stats
}

output_file = 'kmeans_model.pkl'
joblib.dump(model_package, output_file)
print(f"Model kaydedildi: {output_file}")
print()

# Scaler'Ä± ayrÄ± kaydet (app.py uyumluluÄŸu iÃ§in)
scaler_file = 'scaler_model.pkl'
joblib.dump(scaler, scaler_file)
print(f"Scaler kaydedildi: {scaler_file}")
print()

# Ä°ÅŸlenmiÅŸ veriyi kaydet (opsiyonel)
processed_file = 'churn_processed_with_clusters.csv'
df.to_csv(processed_file, index=False)
print(f"Ä°ÅŸlenmiÅŸ veri kaydedildi: {processed_file}")
print()

print("=" * 80)
print("EÄÄ°TÄ°M TAMAMLANDI!")
print("=" * 80)

